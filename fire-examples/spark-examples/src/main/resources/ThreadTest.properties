#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# 非必须配置项：spark 任务的appName，不配置则取类名
# spark.appName                      =       test
spark.log.level                    =       INFO
# 非必须配置项：默认就是这个地址
spark.kafka.brokers.name           =       zms
# 必须配置项：kafka的topic列表，以逗号分隔
spark.kafka.topics                 =       aries_binlog_order
# 非必须配置项：默认为appName
spark.kafka.group.id               =       OrderDetailMainCommon

# ------------------- < hbase 配置 > ------------------- #
# 用于区分不同的hbase集群: batch/streaming/old
spark.hbase.cluster                      =       streaming

# spark的参数可以直接写在下面，都会被加载，覆盖程序中默认的配置信息
spark.speculation                  =       false
spark.streaming.concurrentJobs     =       1