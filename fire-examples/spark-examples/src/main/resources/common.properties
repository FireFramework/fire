# 定义url的别名与url对应关系，后续可通过别名进行配置
spark.db.jdbc.url.map.test          =       jdbc:mysql://192.168.0.1:3306/fire
# 支持别名或直接指定url
spark.db.jdbc.url                   =       test
spark.db.jdbc.driver                =       com.mysql.jdbc.Driver
spark.db.jdbc.user                  =       root
spark.db.jdbc.password              =       root
spark.db.jdbc.batch.size            =       10

# 配置另一个数据源，对应的操作需对应加数字后缀，如：this.spark.jdbcQueryDF2(sql, Seq(1, 2, 3), classOf[Student])
spark.db.jdbc.url2                  =       jdbc:mysql://192.168.0.2:3306/fire2
spark.db.jdbc.driver2               =       com.mysql.jdbc.Driver
spark.db.jdbc.user2                 =       root
spark.db.jdbc.password2             =       root
# 每个批次提交的数据大小，默认1000条
spark.db.jdbc.batch.size2           =       2

spark.db.jdbc.url3                  =       jdbc:mysql://192.168.0.3:3306/fire3
spark.db.jdbc.driver3               =       com.mysql.jdbc.Driver
spark.db.jdbc.user3                 =       root
spark.db.jdbc.password3             =       root
# 事务的隔离级别NONE, READ_COMMITTED, READ_UNCOMMITTED, REPEATABLE_READ, SERIALIZABLE，默认为READ_UNCOMMITTED
spark.db.jdbc.isolation.level3      =       none
# 每个批次插入、更新、删除的数据量，默认为1000
spark.db.jdbc.batch.size3           =       2000

spark.db.jdbc.url5                  =       jdbc:mysql://192.168.0.5:3306/fire5
spark.db.jdbc.driver5               =       com.mysql.jdbc.Driver
spark.db.jdbc.user5                 =       root
spark.db.jdbc.password5             =       root
# 事务的隔离级别NONE, READ_COMMITTED, READ_UNCOMMITTED, REPEATABLE_READ, SERIALIZABLE，默认为READ_UNCOMMITTED
spark.db.jdbc.isolation.level5      =       none
# 每个批次插入、更新、删除的数据量，默认为1000
spark.db.jdbc.batch.size5           =       2000

spark.db.jdbc.url6                  =       jdbc:mysql://192.168.0.6:3306/fire6
spark.db.jdbc.driver6               =       com.mysql.jdbc.Driver
spark.db.jdbc.user6                 =       root
spark.db.jdbc.password6             =       root