#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# spark streaming的remember时间，-1表示不生效(ms)
spark.streaming.remember                                                            =       -1
spark.fire.hbase.scan.partitions                                                    =       20
# spark streaming批次时间，可覆盖代码中所指定的时间
# spark.streaming.batch.duration                                                    =
# 用于在消费多个topic时区分实例
# spark.rocket.consumer.instance                                                    =       driver

# 以下是Spark引擎调优参数
spark.port.maxRetries                                                               =       200
spark.ui.retainedJobs                                                               =       500
spark.ui.killEnabled                                                                =       false
spark.ui.retailedStages                                                             =       300
spark.default.parallelism                                                           =       300
spark.sql.broadcastTimeout                                                          =       3000
spark.streaming.concurrentJobs                                                      =       1
spark.ui.timeline.tasks.maximum                                                     =       300
# 任务通过提交脚本提交到yarn后主动退出提交脚本进程，降低提交节点资源占用（注：此配置需要放到spark-default或提交任务通过--conf指定才会生效）
spark.yarn.submit.waitAppCompletion                                                 =       false
spark.sql.parquet.writeLegacyFormat                                                 =       true
spark.streaming.backpressure.enabled                                                =       true
spark.streaming.stopGracefullyOnShutdown                                            =       true
spark.serializer                                                                    =       org.apache.spark.serializer.KryoSerializer